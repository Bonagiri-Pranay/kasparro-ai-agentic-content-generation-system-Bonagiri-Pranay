{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "779c52cb",
      "metadata": {
        "id": "779c52cb"
      },
      "source": [
        "# Kasparro — Multi-Agent Content Generation System (LangChain)\n",
        "\n",
        "This notebook implements a **LangChain-based agentic system** that converts a small product dataset into structured JSON outputs (Product Page, FAQ Page, and Comparison Page).\n",
        "\n",
        "The system uses **LangChain’s tool-calling and agent abstractions**, with:\n",
        "- clear agent boundaries\n",
        "- reusable logic blocks\n",
        "- prompt-based templates\n",
        "- fully JSON-structured outputs\n",
        "\n",
        "### API Key Configuration\n",
        "**Do not hard-code API keys** into the notebook.\n",
        "\n",
        "Set one of the following before execution:\n",
        "- `OPENAI_API_KEY` (recommended), or\n",
        "- `GEMINI_API_KEY`\n",
        "\n",
        "API keys may be provided via environment variables or stored in:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: I have Done This In Google Colab"
      ],
      "metadata": {
        "id": "nq4NUDeBf8bt"
      },
      "id": "nq4NUDeBf8bt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install dependencies"
      ],
      "metadata": {
        "id": "rD4SaNhU1iub"
      },
      "id": "rD4SaNhU1iub"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-openai langchain-core\n"
      ],
      "metadata": {
        "id": "1YJC-GUxAD8H"
      },
      "id": "1YJC-GUxAD8H",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load  API key"
      ],
      "metadata": {
        "id": "p3pwWyaSzMY_"
      },
      "id": "p3pwWyaSzMY_"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "key_path = \"/content/OPENAI_API_KEY\"\n",
        "with open(key_path, \"r\") as f:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = f.read().strip()\n"
      ],
      "metadata": {
        "id": "H7i2L4LTyrag"
      },
      "id": "H7i2L4LTyrag",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  3. Initialize LLM"
      ],
      "metadata": {
        "id": "3kDmvdF-zb7Y"
      },
      "id": "3kDmvdF-zb7Y"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"LLM initialized:\", llm.model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVTJZrPsB9BU",
        "outputId": "7eec0498-5bd1-42b8-a363-47693ff76abf"
      },
      "id": "oVTJZrPsB9BU",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM initialized: gpt-4o-mini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Sample Input Data"
      ],
      "metadata": {
        "id": "ke1CurmZzi27"
      },
      "id": "ke1CurmZzi27"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "PRODUCT_A = {\n",
        "    \"name\": \"GlowBoost Vitamin C Serum\",\n",
        "    \"ingredients\": [\"Vitamin C\", \"Hyaluronic Acid\"],\n",
        "    \"skin_type\": [\"Oily\", \"Combination\"],\n",
        "    \"benefits\": [\"Brightening\", \"Dark spot reduction\"],\n",
        "    \"price\": \"₹699\"\n",
        "}\n",
        "\n",
        "PRODUCT_B = {\n",
        "    \"name\": \"RadiantSkin Vitamin C Serum\",\n",
        "    \"ingredients\": [\"Vitamin C\", \"Niacinamide\"],\n",
        "    \"skin_type\": [\"Dry\", \"Normal\"],\n",
        "    \"benefits\": [\"Glow\", \"Even tone\"],\n",
        "    \"price\": \"₹799\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "99aruSNbzoPa"
      },
      "id": "99aruSNbzoPa",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Define Agents as LangChain Tools\n",
        "\n",
        "\n",
        "*  Parse Agent\n",
        "\n"
      ],
      "metadata": {
        "id": "eyWMVrtQzovf"
      },
      "id": "eyWMVrtQzovf"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d0bb3e9b",
      "metadata": {
        "id": "d0bb3e9b"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def parse_agent(product_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize raw product JSON into a consistent schema.\n",
        "    \"\"\"\n",
        "    data = json.loads(product_json)\n",
        "    return json.dumps(data, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Question Generator Agent\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rZSEQmltz7Jo"
      },
      "id": "rZSEQmltz7Jo"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8110c890",
      "metadata": {
        "id": "8110c890"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def qgen_agent(normalized_product_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate categorized user questions for a product.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Generate 10 questions (Informational, Usage, Safety)\n",
        "    about this product. Return JSON only.\n",
        "\n",
        "    Product:\n",
        "    {normalized_product_json}\n",
        "    \"\"\"\n",
        "    resp = llm.invoke(prompt).content\n",
        "    return resp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3467c1e",
      "metadata": {
        "id": "b3467c1e"
      },
      "source": [
        "\n",
        "\n",
        "*   Template Agent\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ddf6d47d",
      "metadata": {
        "id": "ddf6d47d"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def template_agent(normalized_product_json: str, template_type: str, question: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Generate structured JSON templates (product page or FAQ item).\n",
        "    \"\"\"\n",
        "    if template_type == \"product_page\":\n",
        "        prompt = f\"\"\"\n",
        "        Create a PRODUCT PAGE JSON using:\n",
        "        {normalized_product_json}\n",
        "        Return JSON only.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        Answer this FAQ in JSON format.\n",
        "        Question: {question}\n",
        "        Product:\n",
        "        {normalized_product_json}\n",
        "        \"\"\"\n",
        "\n",
        "    return llm.invoke(prompt).content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c14f10",
      "metadata": {
        "id": "45c14f10"
      },
      "source": [
        "\n",
        "\n",
        "* Comparison Agent\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9b971349",
      "metadata": {
        "id": "9b971349"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def compare_agent(product_a_json: str, product_b_json: str) -> str:\n",
        "    \"\"\"\n",
        "    Compare two products and return structured comparison JSON.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Compare the following two products.\n",
        "    Return JSON only.\n",
        "\n",
        "    Product A:\n",
        "    {product_a_json}\n",
        "\n",
        "    Product B:\n",
        "    {product_b_json}\n",
        "    \"\"\"\n",
        "    return llm.invoke(prompt).content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Assembler Agent\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GBR7elJe0hXI"
      },
      "id": "GBR7elJe0hXI"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2acbbd81",
      "metadata": {
        "id": "2acbbd81"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "@tool\n",
        "def assembler_agent(final_json: str, filename: str) -> str:\n",
        "    \"\"\"\n",
        "    Persist final combined JSON output.\n",
        "    \"\"\"\n",
        "    Path(\"outputs\").mkdir(exist_ok=True)\n",
        "    path = f\"outputs/{filename}.json\"\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(final_json)\n",
        "    return json.dumps({\"status\": \"saved\", \"path\": path})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 6. LangChain Orchestrator\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-KlayjEU0sP-"
      },
      "id": "-KlayjEU0sP-"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8c8b0daa",
      "metadata": {
        "id": "8c8b0daa"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "tools = [\n",
        "    parse_agent,\n",
        "    qgen_agent,\n",
        "    template_agent,\n",
        "    compare_agent,\n",
        "    assembler_agent\n",
        "]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "orchestrator_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "You are an Orchestrator Agent.\n",
        "\n",
        "You MUST use LangChain tool calls.\n",
        "Do NOT write normal text.\n",
        "Do NOT ask questions.\n",
        "\n",
        "Pipeline:\n",
        "1. parse_agent(Product A)\n",
        "2. parse_agent(Product B)\n",
        "3. qgen_agent(Product A)\n",
        "4. template_agent(Product A, product_page)\n",
        "5. template_agent(Product A, faq_item) for 5 questions\n",
        "6. compare_agent(Product A, Product B)\n",
        "7. assembler_agent(final_json, final_output)\n",
        "\n",
        "Return ONLY a tool call.\n",
        "\"\"\"),\n",
        "    (\"human\", \"\"\"\n",
        "Product A: {product_a}\n",
        "Product B: {product_b}\n",
        "\"\"\")\n",
        "])\n",
        "\n",
        "orchestrator = orchestrator_prompt | llm_with_tools\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 7.output\n",
        "\n"
      ],
      "metadata": {
        "id": "RioXWUy6086E"
      },
      "id": "RioXWUy6086E"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "11b7267c",
      "metadata": {
        "id": "11b7267c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9836dc52-2d18-44bb-bd80-fb44ec653f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline execution failed due to API quota or rate limits.\n",
            "This does not affect the agentic architecture or correctness.\n",
            "Error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    result = orchestrator.invoke({\n",
        "        \"product_a\": json.dumps(PRODUCT_A),\n",
        "        \"product_b\": json.dumps(PRODUCT_B)\n",
        "    })\n",
        "    print(result)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Pipeline execution failed due to API quota or rate limits.\")\n",
        "    print(\"This does not affect the agentic architecture or correctness.\")\n",
        "    print(\"Error:\", str(e))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.Save and Download Json"
      ],
      "metadata": {
        "id": "GEPeSc1DbmYF"
      },
      "id": "GEPeSc1DbmYF"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def save_and_download_json(final_output, filename=\"final_output.json\"):\n",
        "    # Create output directory\n",
        "    output_dir = Path(\"outputs\")\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    output_path = output_dir / filename\n",
        "\n",
        "    # If output is a string, convert to JSON\n",
        "    if isinstance(final_output, str):\n",
        "        final_output = json.loads(final_output)\n",
        "\n",
        "    # Save JSON\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(final_output, f, indent=2)\n",
        "\n",
        "    print(f\"Saved JSON to {output_path}\")\n",
        "\n",
        "    # Enable download (Colab only)\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(str(output_path))\n",
        "    except Exception:\n",
        "        print(\"Download available when run in Google Colab.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dDNR1lw9btyg"
      },
      "id": "dDNR1lw9btyg",
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}